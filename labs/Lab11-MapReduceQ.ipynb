{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"MapReduce\"></a>\n",
    "\n",
    "# Lab 11 - MapReduce \n",
    "\n",
    "***\n",
    "\n",
    "In this lab session we will learn\n",
    "   * Mapper, Reducer and Applications of MapReduce\n",
    "   * Python methods for MapReduce\n",
    "   * Some functions\n",
    "   \n",
    "   \n",
    "Highly recommended to look into the white paper from Google - http://static.googleusercontent.com/media/research.google.com/en/us/archive/mapreduce-osdi04.pdf   \n",
    "   \n",
    "Datasets:\n",
    "\n",
    "[1.] https://www.ssa.gov/oact/babynames/limits.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resources for further readings\n",
    "\n",
    "[1.] https://engineering.purdue.edu/~puma/pumabenchmarks.htm - Classical Mapreduce examples/projects\n",
    "\n",
    "[2.] http://michaelnielsen.org/blog/write-your-first-mapreduce-program-in-20-minutes/ - blog on MapReduce\n",
    "\n",
    "[3.] https://cs.nyu.edu/~mwalfish/classes/16sp/hw/hw3.html - MapReduce with mrjob (working on VM)\n",
    "\n",
    "[4.] https://www.youtube.com/watch?v=30RaNpaupj0&list=PLtzRLOcrx9SS1Ir6_viv-yLJd0PX3GR5O - Video explaining Mapreduce applications:- \n",
    "\n",
    "\n",
    "[5.] https://mapr.com/blog/5-google-projects-changed-big-data-forever/ -  Google Projects that changed the latitude of Big Data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **MapReduce** is a programming model for performing parallel processing on large datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import math, random, re, datetime\n",
    "from collections import defaultdict, Counter\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WordCount - classical way to count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokenize(message):\n",
    "    message = message.lower()                       # convert to lowercase\n",
    "    all_words = re.findall(\"[a-z0-9']+\", message)   # extract the words\n",
    "    return (set(all_words))                           # remove duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the tokenizer is used to split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def word_count_old(documents):\n",
    "    \"\"\" Word count without using map reduce\"\"\"\n",
    "    return Counter (word for document in documents \n",
    "                    for word in tokenize(document))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add text to the document list and observe the output from function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents=[\"data science\",\"big data\", 'data Mining', \"Data Visualization\"]\n",
    "word_counts=word_count_old(documents)\n",
    "print(word_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Read through Chapter 24 of the resource (shared in the lab repository), create a basic function for mapper and reducer for counting the number of words from a list. Print output from each functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mapper\n",
    "\n",
    "* A **Mapper** function returns each item into zero or more key-value pairs.\n",
    "* Map function in python and Map function described here are two different aspects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The mapper functions maps the task\n",
    "def wc_mapper(document):\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reducer\n",
    "\n",
    "* A Reducer function aggregates the *values* corresponding to each *key* i.e., produces output values by grouping together values from each corresponding key.\n",
    "* Aggregation can be anything say summing or fincing maximum or mathematical function\n",
    "* A Reducer loops through the list of key and values and aggregates it. Say sum or max or min or other function\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The reducer function collects the results\n",
    "def wc_reducer(word, counts):\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calling Mapper and reducer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The below function feeds the input data to mapper, consoildates the output from mapper (i.e., collector) \n",
    "# to reducer function and finally output the result from reducer. Map_reduce function!\n",
    "def word_count(documents):\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a list of words related to your area expertise and pass it to your MapReduce function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a list of documents here\n",
    "documents=[\"data science\", \"big data\", \"science fiction\"]\n",
    "word_count(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. MapReduce Paradigm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://pythonhosted.org/mrjob/guides/concepts.html#mapreduce-and-apache-hadoop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 The above link illustrates with an example about the MapReduce paradigm and each functional outputs. Please answer the following\n",
    "\n",
    "### The input file contains a list of technical skills sets extracted from the job applications \"Python, R, Hadoop, SQL\", \"Python, Rshiny, Matlab\", \"R, SQL, Hadoop\", \"SQL, C#, Python\"\n",
    "\n",
    "###  a. What would be the mapping function output for job applicant #1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. What is the output from Shuffling function for python and R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c. If reducer employs the Sum aggregation, what is the most famous programming language among the 4 applicants?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can verify them by applying mapreduce "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skills =[ \"Python, R, Hadoop, SQL\", \"Python, Rshiny, Matlab\", \"R, SQL, Hadoop\", \"SQL, C#, Python\"]\n",
    "\n",
    "word_count(skills)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More generic approach to add both mapper and redcuer in a single function is shown below.\n",
    "\n",
    "#### Binding them all together under a single function - map_reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def map_reduce(inputs, mapper, reducer):\n",
    "    \"\"\"runs MapReduce on input using functions mapper and reducer\"\"\"\n",
    "    collector = defaultdict(list)\n",
    "    \n",
    "    # write a for loop over the inputs that calls mapper\n",
    "    for i in inputs:\n",
    "        for key,value in mapper(i):\n",
    "            collector[key].append(value)\n",
    "    # write a return statement that calls the reducer\n",
    "    return[output\n",
    "          for key,value in collector.items()\n",
    "          for output in reducer(key,value)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts = map_reduce(documents, wc_mapper, wc_reducer)\n",
    "print(word_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 MapReduce Python function\n",
    "\n",
    "Some of the MapReduce function available are:\n",
    "* mapreduce : https://pypi.org/project/mapreduce/\n",
    "* kotti_mapreduce: https://pypi.org/project/kotti_mapreduce/\n",
    "* mrs_mapreduce: https://pypi.org/project/mrs-mapreduce/\n",
    "* mrjob: /pypi.org/project/mrjob/\n",
    "* pydoop 1.2.0 : https://pypi.org/project/pydoop/\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Lets implement the MapReduce on a larger problem \n",
    "\n",
    "#### The dataset reference [1] provides a list of all the baby names that classified according to popular names by state. \n",
    "#### Our task now is to create a function that could load all the files in mapper (). The final goal of the MapReduce is to output the most common words and visualize them using Treemap\n",
    "\n",
    "Reference: Courtesy of UN5550-Fall 2017 assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''Under mapper we would need to extract data from all the files from a folder and \n",
    "tokenize as we did for previous case.\n",
    "\n",
    "we donot want to enter the name of each file that needs to be read, we would need to implement method \n",
    "to read the file contents \n",
    "in the folder and extract the info'''\n",
    "\n",
    "# Loading all necessary libraries\n",
    "import glob, os, fileinput, re, datetime, sys, collections, string \n",
    "from collections import defaultdict, Counter, OrderedDict\n",
    "from functools import partial\n",
    "import pandas as pd     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Function to read all the words from the file\n",
    "def tokenize(message):\n",
    "    message = message.lower()                    \n",
    "    all_words = re.findall(\"[a-z']+\", message)  \n",
    "    return (all_words)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Create a mapper function which works locally to produce a key, value pair for words that start with given letter "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* __Mapper__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The following code would produce mapper output with top 'n' names that start with the letter\n",
    "\n",
    "# mapper function which reads each line in the file on certain condition and returns the key value pairs\n",
    "def mapper1(alpha, filename):\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "        \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* __Reducer__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# reducer function which yields most 'n' common words being used.\n",
    "def reducer1(n, key, wordNcounts):\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* MapReduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def map_reduce(inputs, mapper, reducer):\n",
    "    \"\"\"runs MapReduce on input using functions mapper and reducer\"\"\"\n",
    "    collector = defaultdict(list)\n",
    "    \n",
    "    # write a for loop over the inputs that calls mapper\n",
    "    for i in inputs:\n",
    "        for key,value in mapper(i):\n",
    "            collector[key].append(value)\n",
    "    # write a return statement that calls the reducer\n",
    "    return[output\n",
    "          for key,value in collector.items()\n",
    "          for output in reducer(key,value)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* __Reading all files from a folder, look into options of os libraries__\n",
    "\n",
    "https://docs.python.org/3/library/os.html\n",
    "\n",
    "https://docs.python.org/2/library/functools.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read all the filenames and path in the given directory\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Plotting Treemap\n",
    "\n",
    "An example for plotting treemap is described below: \n",
    "\n",
    "https://python-graph-gallery.com/200-basic-treemap-with-python/\n",
    "\n",
    "There is a necessity to pip install squarify library for building the treemap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --user squarify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Modify the above mapper function to produce a key, value pair for words that contains the given subword say 'an' in all the words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# mapper function which reads each line in the file on certain condition and returns the key value pairs\n",
    "def mapper2(string, filename):\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# reducer function which yields most 'n' common words being used.\n",
    "def reducer2(n, key, wordNcounts):\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main code\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
