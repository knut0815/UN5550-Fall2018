{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Author: Benjamin W. Ong\n",
    "Date: September 9, 2018\n",
    "\n",
    "Goal for this module:\n",
    "* Introduction to data science\n",
    "* Introduction to Jupyter Notebooks\n",
    "* Introduction to Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# What is Data Science?\n",
    "* A systematic approach to infer knowledge from data;\n",
    "* A truly interdisciplinary field that utilizes techniques and theories from, among others, mathematics, statistics, information science and computer science.\n",
    "* Career opportunities across a wide range of industries (common job titles): data scientist, data analyst, data enginer, computer and information research scientist, operations research analyst, ...\n",
    "* Although the discipline of data science is very broad, most employers seek data scientists who \n",
    "    1. have a strong statistical background\n",
    "    2. have a strong analytical background\n",
    "    3. communicate well (both written and oral)\n",
    "* Here is a youtube snippet from a data scientist at a large, un-named tech company, https://www.youtube.com/watch?v=xC-c7E5PK0Y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# UN5550 - Introduction to Data Science\n",
    "This course is intended to give you a broad overview of / gentle introduction to foundational topics in data science.  As part of the broader Masters in Data Science curriculum, you will study various of these topics in depth.\n",
    "\n",
    "Course Objectives:\n",
    "* Proficiency using the Python programming language and awareness of tools/libraries that are available\n",
    "* Proficiency presenting findings using Jupyter notebooks\n",
    "* Proficiency in data management: getting data, cleaning data, dealing with missing data, dimension reduction, exploratory analysis\n",
    "* Appreciation for machine learning: regression, classification and clustering\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# What can you expect from UN 5550?\n",
    "* Weekly lectures on Tuesdays: it will be team taught, although a large percentage will be taught by Ben.  \n",
    "* Lectures taught by Ben will use Jupyter notebooks, which you can edit and run on the fly.\n",
    "* Weekly projects (due Friday at 5pm). You can work in teams of two or three, but each person is responsible for submitting their own notebook -- no plagiarism tolerated! \n",
    "* Weekly labs on Thursdays will be run by the Neelima (TA).  Labs are intended to be a brief review of material covered on Tuesday, and in-depth dive into practical issues related to the project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# My expectations\n",
    "* Come to **every** class\n",
    "* Be respectful\n",
    "* Ask questions\n",
    "* Check your email\n",
    "* Consult course page on Canvas regularly\n",
    "* **Adhere to the MTU academic integrity policy **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Computational Platform\n",
    "Following previous iterations of UN5550, we will primarily be using Python as the computational platform for this course.  \n",
    "* Python is a general high-level programming language that is portable, and recently, highly adopted in the data science community.  \n",
    "* Has many tools and libraries for data analytics, data processing and visualization (funded by DARPA in 2012)\n",
    "* Used across many industries (e.g. social media, finance), at least in the US. \n",
    "* Ben is **NOT** an expert at Python, but I hope to be more proficient by the end of the course.\n",
    "* Your weekly projects are to be done using Jupyter Notebooks.  Why?  Interpreted, east to read code with embedded markdown language. \n",
    "* Lets take some time to setup our environment. https://github.com/ongbw/UN5550-Fall2018/blob/master/installing_python.md\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# About Python\n",
    "* There are two different versions of Python: Python 2.x and Python 3.x\n",
    "* Unfortunately, the versions are not compatible.  Python 2.0 introduced in 2000, Python 3.0 introduced in 2008.  \n",
    "* Most of the scientific community did not immediately change over to Python 3.x, though now most of the libraries have now been ported.\n",
    "* We will use Python 2.7 in this course, to be consistent with the textbook.  You may use Python 3.x if you are comfortable with it, and realize that some comments from the text will be inaccurate.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Python Ecosystem\n",
    "* There are may toolboxes and libraries for data analytics, data processing and visualization\n",
    "* By the end of the course, you should be proficient with:\n",
    "    * NumPy: basic operations for arrays and useful linear algebra functions\n",
    "    * SciPy: collection of numerical algorithms and Matplotlib (for visualization)\n",
    "    * SCIKIT-learn: machine learning (clasification, clustering, dimensionality reduction, model selection, pre-processing)\n",
    "    * PANDAS: data structures and data analysis tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Getting Started\n",
    "* Launch a jupyter notebook by opening a terminal, navigating to an appropriate directory, then typing\n",
    "```shell\n",
    "  jupyter notebook\n",
    "```\n",
    "This should open up a browser window, listing your files in the director.  For now, click New, Python 2 to create your new netebook\n",
    "* Lets import the libraries \n",
    "```python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "```\n",
    "To execute, click on the \"run\" button, or press the Ctrl+Enter keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Frames\n",
    "* The key feature of Pandas is a fast and efficient DataFrame object for data manipulation\n",
    "* A DataFrame is a tabular data structure, with rows and columns.  Lets learn about DataFrames by creating one and manipulating it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\"country\": [\"Canada\",\"USA\",\"Mexico\",\"India\",\"Singapore\",\"China\"], \n",
    "       \"capital\": [\"Ottawa\",\"Washington\",\"Mexico City\",\"New Delhi\",\"Singapore\",\"Beijing\"],\n",
    "       \"population\": [37.0, 327.2, 130.8, 1356.5, 5.8,1415.0]}\n",
    "myworld = pd.DataFrame(data)\n",
    "print(myworld)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the DataFrame object has stored the columns in alphabetical order.  We can arrange it at construction time by entering using the \"columns\" keyword, along with a list of the columns ordered the way we want.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myworld2 = pd.DataFrame(data, columns = [\"country\",\"capital\",\"population\"])\n",
    "print(myworld2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas has also assigned a \"key\" for each row, in this case, with numerical values from 0 through 5.  You can access a subset of rows (observations) using square brackets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(myworld[1:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you only want one column from a DataFrame, you can put the column name in square brackets.  The result will be a series data structure (not a Data Frame) because only one column is retrieved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myworld[\"country\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have some experience with DataFrame objects, lets import a larger data set from a csv file.  We'll use the data/population.csv file, (which can be regenerated if desired with updated data using the WorldbankData.ipynb script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop = pd.read_csv('data/population.csv')\n",
    "pop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the head() function to look at the first few rows, and the tail() function to look at the bottom few rows.  (Default is 5, you can specify number to print in the parenthesis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop.tail(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The describe() function gives quick statistical information on all __numeric__ columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Often, we want to filter data based on some criteria.  For example, if we only care about populations above 1 billion,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop [ pop['Value'] > 1000000000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hmm that was less useful than I expected.  I guess there are many Country names that I wasn't expecting. Lets search specifically for the year 2015.  (For logical statements, don't forget to use parenthesis to generate a series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop [ (pop['Value'] > 1000000000) & (pop['Year']==2015)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A useful way to inspect data is to group according to criteria.  For example, perhaps it would be nice to group all the data by country, regardless of year.  We need to thus aggregate the data in an appropriate fashion.  For example, we could take the mean population (over time) for each country. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group = pop[['Country Name', 'Value']].groupby('Country Name').mean()\n",
    "group.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets explore some data visualization.  Suppose we were interested in plotting the population of China over time.  Lets first create a variable, cn, that extracts data involving china, and then plot that new variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cn = pop[ pop['Country Name']=='China']\n",
    "cn.plot(x=\"Year\",y=\"Value\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or perhaps, we can make use of the aggregate data and plot a pie chart based on the first five entries ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group.head().plot.pie(y='Value')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plotting utilities in MatPlotlib are endless.  If you are new to generating graphs in Python, please review the examples given in the textbook, as well as some examples at: https://pandas.pydata.org/pandas-docs/stable/visualization.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
